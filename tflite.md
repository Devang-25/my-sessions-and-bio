
## Title

TensorFlow Lite and Edge TPU: accelerating your mobile devices with the power of AI

## Title (JP)

TensorFlow Lite と Edge TPU：モバイルアプリをAIで賢くする方法

## Session duration

about 45 min

## Video

[Google I/O session YouTube video](https://www.youtube.com/watch?v=25ISTLhz0ys)

## Target audience and level

Smart phone developers, embedded system designers. Intermediate level (requires no ML expertise)

## Short agenda

TensorFlow Lite is TensorFlow’s lightweight solution for Android, iOS and embedded devices. It enables on-device machine learning inference with low latency and a small binary size. TensorFlow Lite also supports hardware acceleration with the Android Neural Networks API and Apple Core ML. Google also develped Edge TPU, a specialized micro processor for ML predictin at edge devices. In this session, we will discuss how developers can use TensorFlow Lite and Edge TPU to overcome the challenges for bringing the latest AI technology to production mobile apps and embeded systems.

## Abstract (JP):

Googleが提供するオープンソースの機械学習ライブラリTensorFlowのメリットのひとつは、ポータビリティの高さです。学習を終えた
ニューラルネットワークモデルをAndroid等のスマートフォンやRaspberry Pi等のエッジデバイスに載せることで、画像認識や動き検知等、
AIの賢さを活用したさまざまなアプリへの応用が可能です。しかし、アプリへのAI導入の大きな課題は、ニューラルネットワークのモデルサイズと
CPU消費です。そのままではモデルが数10MBの容量に達し、またニューラルネットワークによる認識処理には大きなCPUパワーを必要とします。
そのためGoogleでは、これらの問題を解消する技術として、TensorFlow LiteとEdge TPUを開発しました。このセッションでは、
デバイス向けライブラリ TensorFlow LiteやEdge TPUを用いてスマートフォンアプリやエッジデバイスに最新のAIを導入するための課題や各種手法を解説します。

